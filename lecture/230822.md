# 1 대 1,000,000 사용자를 감당하는 역량의 시작

## 사용자 수 증가에 따른 시스템 설계

처음부터 큰 수를 담을 생각을 하지 않는다.  
처음에는 작게 만들고, 지속적으로 모니터링하면서 개선해 나가는 과정을 거침.  
이걸 해결하기 위해 캐싱을 쓰고, 저걸 해결하기 위해 뭐를 쓰고 등등...

> Scalability(규모 확장성) !!!!!

### 단일 서버 구조

단일 서버에서 웹 앱, 데이터베이스, 캐시 등 모든 컴포넌트가 작동하는 구조.  
프론트/백 구분이 명확하지 않음.

### 다중 서버(프론트엔드 & 백엔드 분리)

SPA(Single Page Application) 방식 등장.  
프론트와 백 개발의 분리.

### 데이터베이스

DB 전용 서버의 등장.  
백엔드 서버가 더 세부적으로 분리된 것.  
이 단계에서는 "어떤 데이터베이스를 사용할 것인가?"가 고려되야함.  
일반적으로 RDBMS 선택.  
비 관계형 데이터베이스도 선택할 수 있으며, 종류가 여러 개로 갈림.  
용도에 따라 DB를 선택하면 된다.

### 사용자 수 증가 - WAS Scale Up vs Scale Out

사용자 증가에 따라 서버 한 대만으로 트래픽 감당 불가능.  
두 가지 방법으로 해결 가능.

1. Scale Up

> 장점

- 수직 방향으로 확장.
- 서버의 CPU, RAM 등의 성능을 높이는 방법.
- 트래픽 양이 적으면 이 방법이 좋음.

> 단점

- 장애 복구(failover) 방안이나, 다중화(re-dundancy) 방안을 제시하기 힘들다.
- 서버 터지면 완전히 중단이 된다.

2. Scale Out

> 장점

- 수평 방향으로 확장.
- 장애 대응이 수월해짐.

> 단점

- 서버 증설로 인해 서버마다 IP 주소가 달라짐.
- 따라서, 유저가 동일한 URL로 접속하는 것이 가능하도록 처리해줄 필요가 있음.

Scale Out의 이런 단점을 해결하는게 로드 밸런서(Load Balancer)!!!

백엔드가 직접 요청을 받지않고, 로드 밸런서(공개 IP)에서 요청을 먼저 받고, 거기서 실제 서버(비공개 IP)로 요청을 보내줌.  
실제 서버(target group이라고 하기도 함.)는 외부에서는 접근할 수 없고, 로드 밸런서를 통해서만 접근 가능.  
즉, 보안 성능 상승.  
확장했을 때도 로드 밸런서에 추가해주면 쉽게 확장이 가능!

로드 밸런서의 특징

- Round Robin 알고리즘을 통해 부하 분산 가능
- Proxy + 보안 기능
- 장애 탐지 및 자동 장애 복구
- 죽은 서버를 판단하고, 분산된 서버로 요청을 보내줌.
- 유저 입장에서는 서버 중 하나가 죽었다는 사실을 인지할 수 없고, 정상 운영되는 것으로 인지됨.
- 로드 밸런서도 부하가 걸리기 때문에, 여러 개의 노드를 두고 사용한다.
- 이런 이유로 대기열을 사용하기도 함. 여러 개 중 하나의 서버는 본인에게 주어진 대기열에서 가져와 요청을 처리함.
- 큐(queue) 같은 것! FIFO!
- 로그 벨런서는 L4 레벨, L7 레벨 등의 구현 방법이 있음.
- 소프트웨어 기반 로드 밸런서 : HAProxy, Nginx, Apache HTTP Server 등
- 클라우드 기반 로드 밸런서 : AWS Elastic Load Balancing(ELB), Azure Load Balancing(ALB) 등

### 사용자 수 증가 - 데이터베이스 다중화(Replication)

master와 slave 구조로 데이터베이스를 설정한다.  
master는 보통 쓰기, slave에서는 읽기를 담당.  
master에 원본 데이터를, slave에서는 사본을 저장.  
읽기가 쓰기에 비해 많기 때문에, 읽기 DB 비중을 많이 둔다.

> 장점

- 장애 탐지 및 장애 복구
- DB 하나가 다운되더라도, 역할을 대체할 수 있음.
- master를 slave가 대체할 수도 있고,
- slave끼리 다른 slave의 빈자리를 대체해줄 수도 있음.

### 캐시를 활용한 Laytency 개선 (1) - In Memory Storage

Laytency = 지연 시간  
보통 1초 이내로 이뤄지게 만들며, 보통 500ms ~ 700ms 사이가 이상적.  
이를 개선할 수 있는게 캐시!

자주 참조되는 데이터나 연산에 비용이 많이 드는 것들을 메모리에 저장하는 방식이다.  
Java, Django는 데이터 캐싱 기능이 있음.

> 동작 원리

1. 캐시에 데이터가 있는 경우 캐시에서 꺼내 쓴다.
2. 없으면, DB에서 데이터를 읽어와 캐시 서버에 저장하고 반환함.

> 주의 사항

- 자주 갱신되는 데이터는 캐시를 하지 말고, 자주 갱신이 없으면서 참조는 많이 되는 데이터를 캐싱하자.
- 메모리에 저장되기 때문에 휘발성 메모리에 저장되도 괜찮은 데이터들. ex) 비용이 많이드는 계산 결과.
- 캐시 데이터 보관 만료 정책에 대해 이해하고 사용할 것. 회사마다, 데이터마다 다름.
- 단일 장애 지점(Single Point of Failure, SPOF)이 되어버릴 가능성이 있으므로, 캐시 서버를 분산할 필요가 있음.
- 캐시 메모리를 어느정도 사용할 것인지에 대한 설정이 필요. 캐시 데이터 사용 용도에 따라 달라짐.
- 데이터 방출(eviction) 정책을 정할 것. 정해진 캐시가 꽉 차면 어떻게 해야할지를 설정. 대표적으로 LRU(Least Recently Used) 정책이 있는데, 최근에 사용된 것들을 판단해서, 가장 사용되지 않은 데이터를 지우는 방법. 여기서도 자료 구조 지식이 필요함!! Linked List가 여기에 적합한 방법임.

### 캐시를 활용한 Laytency 개선 (2) - CDN

물리적으로 분산되어 있는 서버 네트워크.  
정적인 컨텐츠를 빠르고 안정적으로 제공하기 위해 설계됨.  
AWS S3 등등..

오리지널 서버가 가지고 있는 것을 그대로 복제해서 가지고 있는 CDN 서버를 두고,  
요청에 더 빠르게 응답해줄 수 있는 서버에 요청을 보낼 수 있게 하는 것임.

> 주의 사항

- 비용. 데이터 전송 I/O 양에 따라서 요금이 부과됨.
- 만료 기간 설정. S3의 URL에 대한 접근을 무조건 허가하면 보안적인 문제가 있으므로, URL에 접근 권한과 제한 시간을 부여해서 비용 절감과 보안 강화를 진행.

### 다중 데이터 센터 아키텍처

물리적 데이터 센터를 여러 개를 두고 관리하는 방법.  
한쪽이 이슈(재난 등)가 생기더라도, 다른 쪽 서버에서 트래픽을 감당할 수 있도록 하며,  
문제가 있는 곳을 복제해서 빠르게 새로운 곳으로 구축.

### monolithic architecture

확장할 때, 서버가 담당하는 기능들이 똑같은게 계속 늘어나는 구조.  
서버가 담당하고 있는 한 시스템의 오류가 전체 시스템에 영향을 끼친다. 예를들어, 결제 기능에 오류가 생기면 해당 서버의 자원을 결제 기능이 계속 잡아 먹고 있게 됨.  
시스템(기능) 확장 측면에서 효율적이지 않음. 하나의 큰 시스템(서버)에 묶여있기 때문에.  
배포 효율성의 한계점도 명확. 많은 개발자들이 하나의 서버에 계속 배포를 하니까, 기능 개발이 각자 완료될 때마다 서버 전체를 다시 테스트하고 실행하고 배포되고...이런 과정을 거치게 되므로 공수가 너무 들어버리는 문제가 있음.  
개발 효율성의 문제점. 특정 기능은 다른 언어가 더 좋은데, 동일한 코드 베이스에 개발하기 때문에 효율성이 떨어짐. 자바 쓰는 서버는 다른 기능도 자바로 개발을 해야되는 문제랄까..

이들을 해결하기 위해 MSA(Micro Service Architecture) 개념이 등장!!!  
서버 한대는 하나의 기능만 가지고 있다.  
서버1은 유저만, 서버2는 결제만, 서버3는 비디오 스트리밍만.  
각각의 서버는 각각의 로드 밸런서를 가진다.  
이를 통해 다른 기능이 에러가 나도, 다른 기능은 멀쩡하게 돌아감.  
물론, 서버가 서로 통신을 주고받아야 할 수도 있음.  
그런 기능에 한해서는 영향을 받음..  
기능 별 서버 스펙, 개수 등 다양한 확장성을 확보할 수도 있음.

MSA에서 필요한 것이 API Gateway라는 기능이다.  
각 서비스가 물리적으로 나뉘어버리기 때문에, 각 기능의 end point 호출을 위해서는 다른 주소를 사용하게 된다.  
따라서 서비스가 증가하면, 프론트가 기억해야할 주소들이 상당히 복잡해질 가능성이 높음.  
또한, 시스템 내부 구조가 너무 드러나버리고, 트래픽 관리를 전부 따로 확인해야하는 문제가 있다!  
API Gateway는 이름 그대로 이런 API 통신의 입구 역할을 해준다!  
각 기능들의 API들이 하나의 주소만 갖게 만든다!  
API 계의 로드 밸런서랄까..?  
인증 같은 것도 API Gateway를 통해 통합적으로 관리하도록 만들 수도 있음!! 아니면 각 기능 별 서버가 각각 확인해줘야하니까 ㅎㅎ..

### 메시지 큐(Message Queue)

### 데이터베이스의 규모 확장 - 샤딩(Sharding)

데이터 증가하면 하나의 DB가 처리하기 힘들 때가 있음.  
이 때, DB 규모를 확장하는데 두 가지 방법이 있음.

1. Scale Up

- 기존 서버에 CPU, RAM, 하드디스크 등 증설
- 고성능으로 갈 수록 비용이 많이 든다.

2. Scale Out

- col로 쪼개는 방법과 row로 쪼개는 방법이 있음.
- 보통 row로 쪼갬. 이 때 쪼개진 데이터를 샤드라고 함.
- 샤딩 로직을 직접 구현해서, 쪼개진 데이터 베이스로 갈 수 있도록 설정해줘야함. ex) 1~100번 유저는 1번 샤딩으로...
- 단일 DB 서버에서 전체 사용자의 데이터 처리가 힘들 때, 서버 과부하가 발생해 응답 시간이 느려질 때, 샤딩을 고려하자.
- 샤딩 키(key)를 정해야함.
- 물리적으로 서버가 나뉘면, JOIN 쿼리가 안되기 때문에 이런 것도 잘 고려해야함. 글로벌 JOIN을 하려면 여러 가지 방법이 있다. 가장 유명한 것이 비 정규화(de-normalization)

### CI/CD Pipeline 설계

이제는 운영, 관리, 협업하기 편하게 만들어보자.  
MSA 구조는 서버마다 배포를 다 해줘야하기 때문에 일을 많이 해야하는데, CI/CD 자동화를 통해 자동으로 이를 할 수 있음.

### 모니터링 시스템 - 비즈니스 지표와 시스템 지표

모니터링은 매우 중요하다! 시스템을 잘 개발해도, 모니터링을 꾸준히 해주지 않으면 개선하기 힘들다. 안정적인 시스템을 구축하기 위한 매우 중요한 단계!  
Prometheus, Grafana 등으로 사용해서 할 수 있음.  
Prometheus를 통해 서버를 바라보고 모니터링 데이터(매트릭스)를 수집.  
Grafana를 통해 가시화.  
모니터링을 자주 보면서, 프로덕트의 문제의 원인을 찾고 해결해내는 과정을 거쳐, 더 좋은 제품, 더 적은 비용을 이끌어낼 수 있도록!  
크게 비즈니스 지표, 시스템 지표로 나뉨.  
비즈니스 지표는 다양한 고객의 행동에서 발생되는 수치를 말함.  
시스템 지표는 말그대로 서버나 클라우드 시스템 등의 지표.

#### 트래피을 감당하는 두 가지 방법

# 백만 사용자를 위한 대규모 시스템 아키텍처 설계 기초

## 앞에 준비된 화이트보드에 Youtube 시스템을 설계해보세요.

## 설계한 시스템의 용량이나 성능 요구사항을 개략적으로 추정해보세요.

## [면접 질문] 악성 웹 공격 (DDos Attack, SQL Injection Attack)에 어떻게 대응할 수 있겠습니까?

모든 웹 서비스는 공개적으로 인터넷에 노출되어 있다.  
따라서 블랙 해커들이 공격할 수 있는 대상이 됨.  
따라서 프로덕느 내부에 WAF(Web Application Firewall)를 둬야함.  
API Gateway 보다 앞에 WAF를 설치하거나..

## 클라우드 기반 (예: AWS, Google Cloud, Azure) 서비스 구조를 설계해보세요.

## [케이스 스터디] 기업 과제 가이드

## [아하!모먼트] 시스템 설계 면접에 관한 유용한 팁들!
